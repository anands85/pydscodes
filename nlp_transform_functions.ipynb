{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import json\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.neighbors import KNeighborsTransformer\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.sparse import csr_matrix\n",
    "from nlp import load_dataset\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCleanTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Wrapper for using encoding and decoding to clean and transform unstructured text\"\"\"\n",
    "    \n",
    "    #the constructor\n",
    "    def __init__(self, text_cols, encoding_utf8 = True, encoding_replace=True, verbose=True):\n",
    "        \n",
    "        self.text_cols = text_cols\n",
    "        self.encoding_utf8 = encoding_utf8\n",
    "        self.encoding_replace = encoding_replace\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    #estimator method\n",
    "    def fit(self, X, y = None):\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    #transformation\n",
    "    def fit_transform(self, X, y = None):\n",
    "        \n",
    "        process = True\n",
    "        start = datetime.datetime.now()\n",
    "        \n",
    "        try:\n",
    "            if len(self.text_cols)==1:\n",
    "                if self.verbose:\n",
    "                    print('Columns: ', self.text_cols[0])\n",
    "                if self.encoding_utf8 and self.encoding_replace:\n",
    "                    X[self.text_cols[0]] = [x.encode('utf-8','replace') for x in X[self.text_cols[0]]]\n",
    "                elif self.encoding_utf8:\n",
    "                    X[self.text_cols[0]] = [x.encode('utf-8','ignore') for x in X[self.text_cols[0]]]\n",
    "            else:\n",
    "                for col_name in self.text_cols:\n",
    "                    if self.verbose:\n",
    "                        print('Columns: ', col_name)\n",
    "                    if self.encoding_utf8 and self.encoding_replace:\n",
    "                        X[col_name] = [x.encode('utf-8','replace') for x in X[col_name]]\n",
    "                    elif self.encoding_utf8:\n",
    "                        X[col_name] = [x.encode('utf-8','ignore') for x in X[col_name]]\n",
    "        except Exception as err:\n",
    "            if self.verbose:\n",
    "                print('Error: ', err)\n",
    "        end = datetime.datetime.now()\n",
    "        diff = end-start\n",
    "        if self.verbose:\n",
    "            print(diff.seconds)\n",
    "        return X\n",
    "\n",
    "class NMSlibTransformer(TransformerMixin, BaseEstimator):\n",
    "    \"\"\"Wrapper for using nmslib as sklearn's KNeighborsTransformer\"\"\"\n",
    "\n",
    "    def __init__(self, n_neighbors=5, metric=\"euclidean\", method=\"sw-graph\", n_jobs=1):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.method = method\n",
    "        self.metric = metric\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.n_samples_fit_ = X.shape[0]\n",
    "\n",
    "        # see more metric in the manual\n",
    "        # https://github.com/nmslib/nmslib/tree/master/manual\n",
    "        space = {\n",
    "            \"euclidean\": \"l2\",\n",
    "            \"cosine\": \"cosinesimil\",\n",
    "            \"l1\": \"l1\",\n",
    "            \"l2\": \"l2\",\n",
    "        }[self.metric]\n",
    "\n",
    "        self.nmslib_ = nmslib.init(method=self.method, space=space)\n",
    "        self.nmslib_.addDataPointBatch(X)\n",
    "        self.nmslib_.createIndex()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        n_samples_transform = X.shape[0]\n",
    "\n",
    "        # For compatibility reasons, as each sample is considered as its own\n",
    "        # neighbor, one extra neighbor will be computed.\n",
    "        n_neighbors = self.n_neighbors + 1\n",
    "\n",
    "        results = self.nmslib_.knnQueryBatch(X, k=n_neighbors, num_threads=self.n_jobs)\n",
    "        indices, distances = zip(*results)\n",
    "        indices, distances = np.vstack(indices), np.vstack(distances)\n",
    "\n",
    "        indptr = np.arange(0, n_samples_transform * n_neighbors + 1, n_neighbors)\n",
    "        kneighbors_graph = csr_matrix(\n",
    "            (distances.ravel(), indices.ravel(), indptr),\n",
    "            shape=(n_samples_transform, self.n_samples_fit_),\n",
    "        )\n",
    "\n",
    "        return kneighbors_graph\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/neighbors/approximate_nearest_neighbors.html#sphx-glr-auto-examples-neighbors-approximate-nearest-neighbors-py\n",
    "class AnnoyTransformer(TransformerMixin, BaseEstimator):\n",
    "    \"\"\"Wrapper for using annoy.AnnoyIndex as sklearn's KNeighborsTransformer\"\"\"\n",
    "\n",
    "    def __init__(self, n_neighbors=5, metric=\"euclidean\", n_trees=10, search_k=-1):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.n_trees = n_trees\n",
    "        self.search_k = search_k\n",
    "        self.metric = metric\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.n_samples_fit_ = X.shape[0]\n",
    "        self.annoy_ = annoy.AnnoyIndex(X.shape[1], metric=self.metric)\n",
    "        for i, x in enumerate(X):\n",
    "            self.annoy_.add_item(i, x.tolist())\n",
    "        self.annoy_.build(self.n_trees)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self._transform(X)\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X)._transform(X=None)\n",
    "\n",
    "    def _transform(self, X):\n",
    "        \"\"\"As `transform`, but handles X is None for faster `fit_transform`.\"\"\"\n",
    "\n",
    "        n_samples_transform = self.n_samples_fit_ if X is None else X.shape[0]\n",
    "\n",
    "        # For compatibility reasons, as each sample is considered as its own\n",
    "        # neighbor, one extra neighbor will be computed.\n",
    "        n_neighbors = self.n_neighbors + 1\n",
    "\n",
    "        indices = np.empty((n_samples_transform, n_neighbors), dtype=int)\n",
    "        distances = np.empty((n_samples_transform, n_neighbors))\n",
    "\n",
    "        if X is None:\n",
    "            for i in range(self.annoy_.get_n_items()):\n",
    "                ind, dist = self.annoy_.get_nns_by_item(\n",
    "                    i, n_neighbors, self.search_k, include_distances=True\n",
    "                )\n",
    "\n",
    "                indices[i], distances[i] = ind, dist\n",
    "        else:\n",
    "            for i, x in enumerate(X):\n",
    "                indices[i], distances[i] = self.annoy_.get_nns_by_vector(\n",
    "                    x.tolist(), n_neighbors, self.search_k, include_distances=True\n",
    "                )\n",
    "\n",
    "        indptr = np.arange(0, n_samples_transform * n_neighbors + 1, n_neighbors)\n",
    "        kneighbors_graph = csr_matrix(\n",
    "            (distances.ravel(), indices.ravel(), indptr),\n",
    "            shape=(n_samples_transform, self.n_samples_fit_),\n",
    "        )\n",
    "\n",
    "        return kneighbors_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_case():\n",
    "    dataset = load_dataset('glue', 'mrpc', split='train')\n",
    "    eg_dataset_df = pd.DataFrame([dataset['sentence1'],dataset['sentence2'],dataset['label']]).T\n",
    "    eg_dataset_df.columns = ['sentence1','sentence2','label']\n",
    "    print(eg_dataset_df)\n",
    "    #the numeric attributes transformation pipeline\n",
    "    text_pipeline = Pipeline([\n",
    "            ('text_clean', TextCleanTransformer(['sentence1','sentence2'],True,True))])\n",
    "    #perform the fit transform\n",
    "    eg_dataset_df_clean = text_pipeline.fit_transform(eg_dataset_df)\n",
    "    print(eg_dataset_df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              sentence1  \\\n",
      "0     Amrozi accused his brother , whom he called \" ...   \n",
      "1     Yucaipa owned Dominick 's before selling the c...   \n",
      "2     They had published an advertisement on the Int...   \n",
      "3     Around 0335 GMT , Tab shares were up 19 cents ...   \n",
      "4     The stock rose $ 2.11 , or about 11 percent , ...   \n",
      "...                                                 ...   \n",
      "3663  \" At this point , Mr. Brando announced : ' Som...   \n",
      "3664  Martin , 58 , will be freed today after servin...   \n",
      "3665  \" We have concluded that the outlook for price...   \n",
      "3666  The notification was first reported Friday by ...   \n",
      "3667  The 30-year bond US30YT = RR rose 22 / 32 for ...   \n",
      "\n",
      "                                              sentence2 label  \n",
      "0     Referring to him as only \" the witness \" , Amr...     1  \n",
      "1     Yucaipa bought Dominick 's in 1995 for $ 693 m...     0  \n",
      "2     On June 10 , the ship 's owners had published ...     1  \n",
      "3     Tab shares jumped 20 cents , or 4.6 % , to set...     0  \n",
      "4     PG & E Corp. shares jumped $ 1.63 or 8 percent...     1  \n",
      "...                                                 ...   ...  \n",
      "3663  Brando said that \" somebody ought to put a bul...     1  \n",
      "3664  Martin served two thirds of a five-year senten...     0  \n",
      "3665  In a statement , the ECB said the outlook for ...     1  \n",
      "3666  MSNBC.com first reported the CIA request on Fr...     1  \n",
      "3667  The 30-year bond US30YT = RR grew 1-3 / 32 for...     0  \n",
      "\n",
      "[3668 rows x 3 columns]\n",
      "sentence1\n",
      "sentence2\n",
      "0\n",
      "                                              sentence1  \\\n",
      "0     b'Amrozi accused his brother , whom he called ...   \n",
      "1     b\"Yucaipa owned Dominick 's before selling the...   \n",
      "2     b'They had published an advertisement on the I...   \n",
      "3     b'Around 0335 GMT , Tab shares were up 19 cent...   \n",
      "4     b'The stock rose $ 2.11 , or about 11 percent ...   \n",
      "...                                                 ...   \n",
      "3663  b'\" At this point , Mr. Brando announced : \\' ...   \n",
      "3664  b'Martin , 58 , will be freed today after serv...   \n",
      "3665  b'\" We have concluded that the outlook for pri...   \n",
      "3666  b'The notification was first reported Friday b...   \n",
      "3667  b\"The 30-year bond US30YT = RR rose 22 / 32 fo...   \n",
      "\n",
      "                                              sentence2 label  \n",
      "0     b'Referring to him as only \" the witness \" , A...     1  \n",
      "1     b\"Yucaipa bought Dominick 's in 1995 for $ 693...     0  \n",
      "2     b\"On June 10 , the ship 's owners had publishe...     1  \n",
      "3     b'Tab shares jumped 20 cents , or 4.6 % , to s...     0  \n",
      "4     b'PG & E Corp. shares jumped $ 1.63 or 8 perce...     1  \n",
      "...                                                 ...   ...  \n",
      "3663  b'Brando said that \" somebody ought to put a b...     1  \n",
      "3664  b'Martin served two thirds of a five-year sent...     0  \n",
      "3665  b'In a statement , the ECB said the outlook fo...     1  \n",
      "3666  b'MSNBC.com first reported the CIA request on ...     1  \n",
      "3667  b'The 30-year bond US30YT = RR grew 1-3 / 32 f...     0  \n",
      "\n",
      "[3668 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "test_case()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
