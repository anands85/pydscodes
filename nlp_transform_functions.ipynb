{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import json\n",
    "import string\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from nlp import load_dataset\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###https://www.analyticsvidhya.com/blog/2021/06/text-preprocessing-in-nlp-with-python-codes/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDecodeXFormer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Wrapper for using encoding and decoding to clean and transform unstructured text\"\"\"\n",
    "    \n",
    "    #the constructor\n",
    "    def __init__(self, text_cols, encoding_utf8 = True, encoding_replace=True, verbose=True):\n",
    "        self.text_cols = text_cols\n",
    "        self.encoding_utf8 = encoding_utf8\n",
    "        self.encoding_replace = encoding_replace\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    #estimator method\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)\n",
    "    \n",
    "    #transformation\n",
    "    def transform(self, X, y = None):\n",
    "        process = True\n",
    "        start = datetime.datetime.now()\n",
    "        try:\n",
    "            if len(self.text_cols)==1:\n",
    "                if self.verbose:\n",
    "                    print('Columns: ', self.text_cols[0])\n",
    "                if self.encoding_utf8 and self.encoding_replace:\n",
    "                    X[self.text_cols[0]] = [str(x.encode('utf-8','replace')) for x in X[self.text_cols[0]]]\n",
    "                elif self.encoding_utf8:\n",
    "                    X[self.text_cols[0]] = [str(x.encode('utf-8','ignore')) for x in X[self.text_cols[0]]]\n",
    "            else:\n",
    "                for col_name in self.text_cols:\n",
    "                    if self.verbose:\n",
    "                        print('Columns: ', col_name)\n",
    "                    if self.encoding_utf8 and self.encoding_replace:\n",
    "                        X[col_name] = [str(x.encode('utf-8','replace')) for x in X[col_name]]\n",
    "                    elif self.encoding_utf8:\n",
    "                        X[col_name] = [str(x.encode('utf-8','ignore')) for x in X[col_name]]\n",
    "        except Exception as err:\n",
    "            if self.verbose:\n",
    "                print('Error: ', err)\n",
    "        end = datetime.datetime.now()\n",
    "        diff = end-start\n",
    "        if self.verbose:\n",
    "            print(diff.seconds)\n",
    "        return X\n",
    "    \n",
    "class RemovePunctuationXFormer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Wrapper for using encoding and decoding to clean and transform unstructured text\"\"\"\n",
    "    #the constructor\n",
    "    def __init__(self, punc_list = [], ignore_list=[], replace_string='\\s', verbose = True):\n",
    "        self.ignore_list = ignore_list\n",
    "        self.replace_string = replace_string\n",
    "        self.verbose = verbose\n",
    "        if len(punc_list)==0:\n",
    "            self.punc_list = []\n",
    "            for character in string.punctuation:\n",
    "                self.punc_list.append(str(character))\n",
    "        else:\n",
    "            self.punc_list = punc_list\n",
    "        \n",
    "    #estimator method\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)\n",
    "    \n",
    "    #transformation\n",
    "    def transform(self, X, y = None):\n",
    "        process = True\n",
    "        start = datetime.datetime.now()\n",
    "        self.text_cols = X.columns\n",
    "        try:\n",
    "            if len(self.text_cols)==1:\n",
    "                if self.verbose:\n",
    "                    print('Columns: ', self.text_cols[0])\n",
    "                X[self.text_cols[0]] = [\"\".join([i if (i not in self.punc_list or i in self.ignore_list) else self.replace_string for i in x]) for x in X[self.text_cols[0]]]  \n",
    "            else:\n",
    "                for col_name in self.text_cols:\n",
    "                    if self.verbose:\n",
    "                        print('Columns: ', col_name)\n",
    "                    X[col_name] = [\"\".join([i if (i not in self.punc_list or i in self.ignore_list) else self.replace_string for i in x]) for x in X[col_name]]   \n",
    "        except Exception as err:\n",
    "            if self.verbose:\n",
    "                print('Error: ', err)\n",
    "        end = datetime.datetime.now()\n",
    "        diff = end-start\n",
    "        if self.verbose:\n",
    "            print(diff.seconds)\n",
    "        return X\n",
    "    \n",
    "class LowerTextXFormer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, verbose = True):\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        process = True\n",
    "        start = datetime.datetime.now()\n",
    "        self.text_cols = X.columns\n",
    "        try:\n",
    "            if len(self.text_cols)==1:\n",
    "                if self.verbose:\n",
    "                    print('Columns: ', self.text_cols[0])\n",
    "                X[self.text_cols[0]] = X[self.text_cols[0]].apply(lambda x: x.lower()) \n",
    "            else:\n",
    "                for col_name in self.text_cols:\n",
    "                    if self.verbose:\n",
    "                        print('Columns: ', col_name)\n",
    "                    X[col_name] = X[col_name].apply(lambda x: x.lower())\n",
    "        except Exception as err:\n",
    "            if self.verbose:\n",
    "                print('Error: ', err)\n",
    "        end = datetime.datetime.now()\n",
    "        diff = end-start\n",
    "        if self.verbose:\n",
    "            print(diff.seconds)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_case():\n",
    "    dataset = load_dataset('glue', 'mrpc', split='train')\n",
    "    eg_dataset_df = pd.DataFrame([dataset['sentence1'],dataset['sentence2'],dataset['label']]).T\n",
    "    eg_dataset_df.columns = ['sentence1','sentence2','label']\n",
    "    print(eg_dataset_df.head(1).values)\n",
    "    #the numeric attributes transformation pipeline\n",
    "    punc_list = []\n",
    "    for character in string.punctuation:\n",
    "        punc_list.append(str(character))\n",
    "    text_pipeline = Pipeline([\n",
    "        ('text_decode', TextDecodeXFormer(text_cols = ['sentence1','sentence2'],\n",
    "                                              encoding_utf8 = True, \n",
    "                                              encoding_replace = False)),\n",
    "        ('remove_punctuation',RemovePunctuationXFormer(punc_list = punc_list,\n",
    "                                                        ignore_list = [',','?','.'],\n",
    "                                                        replace_string='*')),\n",
    "        ('lower_text',LowerTextXFormer())\n",
    "    ])\n",
    "    #perform the fit transform\n",
    "    eg_dataset_df_clean = text_pipeline.fit_transform(eg_dataset_df)\n",
    "    print(eg_dataset_df_clean.head(1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .'\n",
      "  'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .'\n",
      "  1]]\n",
      "Columns:  sentence1\n",
      "Columns:  sentence2\n",
      "0\n",
      "Columns:  sentence1\n",
      "Columns:  sentence2\n",
      "Columns:  label\n",
      "Error:  'int' object is not iterable\n",
      "0\n",
      "Columns:  sentence1\n",
      "Columns:  sentence2\n",
      "Columns:  label\n",
      "Error:  'int' object has no attribute 'lower'\n",
      "0\n",
      "[['b*amrozi accused his brother , whom he called * the witness * , of deliberately distorting his evidence .*'\n",
      "  'b*referring to him as only * the witness * , amrozi accused his brother of deliberately distorting his evidence .*'\n",
      "  1]]\n"
     ]
    }
   ],
   "source": [
    "test_case()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test functions separately to get the right outputs\n",
    "\n",
    "string_data = 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .'\n",
    "punc_list = []\n",
    "for character in string.punctuation:\n",
    "    punc_list.append(str(character))\n",
    "print(punc_list)\n",
    "ignore_list = [',','?','.']\n",
    "replace_string = '*'\n",
    "string_clean= [\"\".join([i if (i not in punc_list or i in ignore_list) else replace_string for i in string_data])]\n",
    "print(string_data)\n",
    "print(string_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsTransformer\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "class NMSlibTransformer(TransformerMixin, BaseEstimator):\n",
    "    \"\"\"Wrapper for using nmslib as sklearn's KNeighborsTransformer\"\"\"\n",
    "\n",
    "    def __init__(self, n_neighbors=5, metric=\"euclidean\", method=\"sw-graph\", n_jobs=1):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.method = method\n",
    "        self.metric = metric\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.n_samples_fit_ = X.shape[0]\n",
    "\n",
    "        # see more metric in the manual\n",
    "        # https://github.com/nmslib/nmslib/tree/master/manual\n",
    "        space = {\n",
    "            \"euclidean\": \"l2\",\n",
    "            \"cosine\": \"cosinesimil\",\n",
    "            \"l1\": \"l1\",\n",
    "            \"l2\": \"l2\",\n",
    "        }[self.metric]\n",
    "\n",
    "        self.nmslib_ = nmslib.init(method=self.method, space=space)\n",
    "        self.nmslib_.addDataPointBatch(X)\n",
    "        self.nmslib_.createIndex()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        n_samples_transform = X.shape[0]\n",
    "\n",
    "        # For compatibility reasons, as each sample is considered as its own\n",
    "        # neighbor, one extra neighbor will be computed.\n",
    "        n_neighbors = self.n_neighbors + 1\n",
    "\n",
    "        results = self.nmslib_.knnQueryBatch(X, k=n_neighbors, num_threads=self.n_jobs)\n",
    "        indices, distances = zip(*results)\n",
    "        indices, distances = np.vstack(indices), np.vstack(distances)\n",
    "\n",
    "        indptr = np.arange(0, n_samples_transform * n_neighbors + 1, n_neighbors)\n",
    "        kneighbors_graph = csr_matrix(\n",
    "            (distances.ravel(), indices.ravel(), indptr),\n",
    "            shape=(n_samples_transform, self.n_samples_fit_),\n",
    "        )\n",
    "\n",
    "        return kneighbors_graph\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/neighbors/approximate_nearest_neighbors.html#sphx-glr-auto-examples-neighbors-approximate-nearest-neighbors-py\n",
    "class AnnoyTransformer(TransformerMixin, BaseEstimator):\n",
    "    \"\"\"Wrapper for using annoy.AnnoyIndex as sklearn's KNeighborsTransformer\"\"\"\n",
    "\n",
    "    def __init__(self, n_neighbors=5, metric=\"euclidean\", n_trees=10, search_k=-1):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.n_trees = n_trees\n",
    "        self.search_k = search_k\n",
    "        self.metric = metric\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.n_samples_fit_ = X.shape[0]\n",
    "        self.annoy_ = annoy.AnnoyIndex(X.shape[1], metric=self.metric)\n",
    "        for i, x in enumerate(X):\n",
    "            self.annoy_.add_item(i, x.tolist())\n",
    "        self.annoy_.build(self.n_trees)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self._transform(X)\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X)._transform(X=None)\n",
    "\n",
    "    def _transform(self, X):\n",
    "        \"\"\"As `transform`, but handles X is None for faster `fit_transform`.\"\"\"\n",
    "\n",
    "        n_samples_transform = self.n_samples_fit_ if X is None else X.shape[0]\n",
    "\n",
    "        # For compatibility reasons, as each sample is considered as its own\n",
    "        # neighbor, one extra neighbor will be computed.\n",
    "        n_neighbors = self.n_neighbors + 1\n",
    "\n",
    "        indices = np.empty((n_samples_transform, n_neighbors), dtype=int)\n",
    "        distances = np.empty((n_samples_transform, n_neighbors))\n",
    "\n",
    "        if X is None:\n",
    "            for i in range(self.annoy_.get_n_items()):\n",
    "                ind, dist = self.annoy_.get_nns_by_item(\n",
    "                    i, n_neighbors, self.search_k, include_distances=True\n",
    "                )\n",
    "\n",
    "                indices[i], distances[i] = ind, dist\n",
    "        else:\n",
    "            for i, x in enumerate(X):\n",
    "                indices[i], distances[i] = self.annoy_.get_nns_by_vector(\n",
    "                    x.tolist(), n_neighbors, self.search_k, include_distances=True\n",
    "                )\n",
    "\n",
    "        indptr = np.arange(0, n_samples_transform * n_neighbors + 1, n_neighbors)\n",
    "        kneighbors_graph = csr_matrix(\n",
    "            (distances.ravel(), indices.ravel(), indptr),\n",
    "            shape=(n_samples_transform, self.n_samples_fit_),\n",
    "        )\n",
    "\n",
    "        return kneighbors_graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
